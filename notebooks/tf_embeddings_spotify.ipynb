{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a22ea4f7-3b6b-4554-aeda-ae85e7f96f0a",
   "metadata": {},
   "source": [
    "# Work on embeddings\n",
    "\n",
    "Objective: Take Podcast Descriptions and Benchmark Creating Embeddings.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bcf087d1-9581-4d00-89e4-11765da5cbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import altair as alt\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import time\n",
    "import pickle\n",
    "import tqdm\n",
    "import os\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "from transformers import AutoTokenizer, TFAutoModel\n",
    "import tensorflow as tf\n",
    "import yaml\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bbc6293-5ace-402f-a028-630dfd259861",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea783ca8-cf7b-44f8-9908-f1c9eb5da55b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90706, 18)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../../metadata_with_episode_dates_and_category.tsv',sep='\\t')\n",
    "df['release_date'] = pd.to_datetime(df['release_date'], format='%Y-%m-%d').reset_index(drop=True)\n",
    "df = df[~df['release_date'].isna()]\n",
    "df = df[~df['category'].isna()]\n",
    "df = df[~df['show_description'].isna()]\n",
    "df = df[~df['show_name'].isna()]\n",
    "df = df[~df['episode_description'].isna()]\n",
    "df = df[~df['episode_name'].isna()]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "e88f36ae-6d09-4c25-adce-d0a3c97ad7f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shows: 15857, Episodes: 90871\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shows: {len(show_descriptions)}, Episodes: {len(episode_descriptions)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9dbe39-25a3-4d53-8735-dcb3cef6d3b7",
   "metadata": {},
   "source": [
    "# Create an Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5dc47852-b743-48d4-8e03-eecc2c71dc4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-23 15:54:45.452458: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1\n",
      "2023-11-23 15:54:45.452480: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2023-11-23 15:54:45.452484: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2023-11-23 15:54:45.452632: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:303] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-11-23 15:54:45.452803: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:269] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "All model checkpoint layers were used when initializing TFBertModel.\n",
      "\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at sentence-transformers/multi-qa-MiniLM-L6-cos-v1.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "#Mean Pooling - Take attention mask into account for correct averaging\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output.last_hidden_state\n",
    "    input_mask_expanded = tf.cast(tf.tile(tf.expand_dims(attention_mask, -1), [1, 1, token_embeddings.shape[-1]]), tf.float32)\n",
    "    return tf.math.reduce_sum(token_embeddings * input_mask_expanded, 1) / tf.math.maximum(tf.math.reduce_sum(input_mask_expanded, 1), 1e-9)\n",
    "\n",
    "\n",
    "#Encode text\n",
    "def encode(texts):\n",
    "    # Tokenize sentences\n",
    "    encoded_input = tokenizer(texts, padding=True, truncation=True, return_tensors='tf')\n",
    "\n",
    "    # Compute token embeddings\n",
    "    model_output = model(**encoded_input, return_dict=True)\n",
    "\n",
    "    # Perform pooling\n",
    "    embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "\n",
    "    # Normalize embeddings\n",
    "    embeddings = tf.math.l2_normalize(embeddings, axis=1)\n",
    "\n",
    "    return embeddings\n",
    "\n",
    "# Load model from HuggingFace Hub\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/multi-qa-MiniLM-L6-cos-v1\")\n",
    "model = TFAutoModel.from_pretrained(\"sentence-transformers/multi-qa-MiniLM-L6-cos-v1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9251cb4-301c-4aa1-98b9-58be8a034820",
   "metadata": {},
   "source": [
    "# Benchmark Making Show Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4b04f5ae-79db-48db-a5d7-de5c6653d459",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shows = df.drop_duplicates(['show_name','show_description'])[['show_name','show_description']].reset_index(drop=True)\n",
    "show_descriptions = list(df_shows['show_description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "28228ae9-8944-4839-aaee-753c5dc60990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08s: 1 Show Embedding(s)\n",
      "0.04s: 3 Show Embedding(s)\n",
      "0.08s: 10 Show Embedding(s)\n",
      "0.24s: 30 Show Embedding(s)\n",
      "1.04s: 100 Show Embedding(s)\n"
     ]
    }
   ],
   "source": [
    "# Note: on show description embedding size of 1000, my macbook ran out of memory.\n",
    "t = []\n",
    "number_of_embeddings = [1, 3, 10, 30, 100]\n",
    "for i in number_of_embeddings:\n",
    "    start = time.time()\n",
    "    shows_embeddings = encode(show_descriptions[:i])\n",
    "    end = time.time()\n",
    "    t.append(end-start)\n",
    "    print(f\"{end-start:.2f}s: {i} Show Embedding(s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "66fc0b4b-bbbd-484e-a521-d608a129a5ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Show Embeddings size: 30.  Maximizes Embeddings Per Second on my local machine\n"
     ]
    }
   ],
   "source": [
    "# take the embedding size trials and then take the argmax of the Embeddings Per Second Metric\n",
    "# which gives you the best index from number_of_embeddings.  this becomes the best_size.\n",
    "embeddings_per_sec = np.array(number_of_embeddings) / np.array(t)\n",
    "best_index = np.argmax(embeddings_per_sec)\n",
    "best_size = embedding_size_trials[best_index]\n",
    "print(f\"Best Show Embeddings size: {best_size}.  Maximizes Embeddings Per Second on my local machine\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8e25ef85-00d2-4c0e-b06f-3bc8b19fbd90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimate 2.12 minutes to create all show embeddings.\n"
     ]
    }
   ],
   "source": [
    "# To attempt embeddings for each show...\n",
    "# create 30 embeddings at a time would take: \n",
    "print(f\"Estimate {df_shows.shape[0] / embeddings_per_sec[best_index] / 60 :.2f} minutes to create all show embeddings.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8401edc7-9a56-4fc9-ac60-81f4ab8f77b0",
   "metadata": {},
   "source": [
    "# Benchmark Making Episode Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9c776b4f-ad81-4403-ae57-68b1d132406d",
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_descriptions = list(df['episode_description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3e80961b-ba11-4b1c-a661-39c8b098ad43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19s: 1 Episode Embedding(s)\n",
      "0.17s: 3 Episode Embedding(s)\n",
      "0.24s: 10 Episode Embedding(s)\n",
      "1.97s: 30 Episode Embedding(s)\n",
      "4.68s: 100 Episode Embedding(s)\n"
     ]
    }
   ],
   "source": [
    "# Note: on show description embedding size of 1000, my macbook ran out of memory.\n",
    "t = []\n",
    "number_of_embeddings = [1, 3, 10, 30, 100]\n",
    "for i in number_of_embeddings:\n",
    "    start = time.time()\n",
    "    episode_embeddings = encode(episode_descriptions[:i])\n",
    "    end = time.time()\n",
    "    t.append(end-start)\n",
    "    print(f\"{end-start:.2f}s: {i} Episode Embedding(s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "35e766e4-f609-4caf-b365-ee4175c9eddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Episode Embeddings size: 10.  Maximizes Embeddings Per Second on my local machine\n"
     ]
    }
   ],
   "source": [
    "# take the embedding size trials and then take the argmax of the Embeddings Per Second Metric\n",
    "# which gives you the best index from number_of_embeddings.  this becomes the best_size.\n",
    "embeddings_per_sec = np.array(number_of_embeddings) / np.array(t)\n",
    "best_index = np.argmax(embeddings_per_sec)\n",
    "best_size = embedding_size_trials[best_index]\n",
    "print(f\"Best Episode Embeddings size: {best_size}.  Maximizes Embeddings Per Second on my local machine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bc292021-b450-4dc6-ad21-ac63b9168335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimate 36.13 minutes to create all episode embeddings.\n"
     ]
    }
   ],
   "source": [
    "# To attempt embeddings for each show...\n",
    "# create 30 embeddings at a time would take: \n",
    "print(f\"Estimate {df.shape[0] / embeddings_per_sec[best_index] / 60 :.2f} minutes to create all episode embeddings.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
