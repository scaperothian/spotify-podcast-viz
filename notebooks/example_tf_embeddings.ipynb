{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a22ea4f7-3b6b-4554-aeda-ae85e7f96f0a",
   "metadata": {},
   "source": [
    "# Work on embeddings\n",
    "\n",
    "Objective: Take Podcast Descriptions and create embeddings from them.  Create an application that allows a user to enter their own text and use cosine similarity to find the most similar show descriptions (or episodes based on episode description).  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "bcf087d1-9581-4d00-89e4-11765da5cbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import altair as alt\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import time\n",
    "import pickle\n",
    "import tqdm\n",
    "sns.set_style('darkgrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "ea783ca8-cf7b-44f8-9908-f1c9eb5da55b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90871, 18)"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../../metadata_with_episode_dates_and_category.tsv',sep='\\t')\n",
    "df['release_date'] = pd.to_datetime(df['release_date'], format='%Y-%m-%d').reset_index(drop=True)\n",
    "df = df[~df['release_date'].isna()]\n",
    "df = df[~df['category'].isna()]\n",
    "df = df[~df['show_description'].isna()]\n",
    "df = df[~df['show_name'].isna()]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "4599085b-7d8b-4677-ad3b-79cca4c5cd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, TFAutoModel\n",
    "import tensorflow as tf\n",
    "import yaml\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "e88f36ae-6d09-4c25-adce-d0a3c97ad7f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shows: 15857, Episodes: 90871\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shows: {len(show_descriptions)}, Episodes: {len(episode_descriptions)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "5dc47852-b743-48d4-8e03-eecc2c71dc4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertModel.\n",
      "\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at sentence-transformers/multi-qa-MiniLM-L6-cos-v1.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "#Mean Pooling - Take attention mask into account for correct averaging\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output.last_hidden_state\n",
    "    input_mask_expanded = tf.cast(tf.tile(tf.expand_dims(attention_mask, -1), [1, 1, token_embeddings.shape[-1]]), tf.float32)\n",
    "    return tf.math.reduce_sum(token_embeddings * input_mask_expanded, 1) / tf.math.maximum(tf.math.reduce_sum(input_mask_expanded, 1), 1e-9)\n",
    "\n",
    "\n",
    "#Encode text\n",
    "def encode(texts):\n",
    "    # Tokenize sentences\n",
    "    encoded_input = tokenizer(texts, padding=True, truncation=True, return_tensors='tf')\n",
    "\n",
    "    # Compute token embeddings\n",
    "    model_output = model(**encoded_input, return_dict=True)\n",
    "\n",
    "    # Perform pooling\n",
    "    embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "\n",
    "    # Normalize embeddings\n",
    "    embeddings = tf.math.l2_normalize(embeddings, axis=1)\n",
    "\n",
    "    return embeddings\n",
    "\n",
    "# Load model from HuggingFace Hub\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/multi-qa-MiniLM-L6-cos-v1\")\n",
    "model = TFAutoModel.from_pretrained(\"sentence-transformers/multi-qa-MiniLM-L6-cos-v1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6909a82a-209d-47e9-af7e-bba9e7ad3836",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Example from Huggingface\n",
    "https://huggingface.co/sentence-transformers/multi-qa-MiniLM-L6-cos-v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "47cdf890-cc9f-47f6-9852-fddad6d7b19e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.92, Query: Around 9 Million people live in London.\n",
      "Score: 0.49, Query: London is known for its financial district.\n"
     ]
    }
   ],
   "source": [
    "# Sentences we want sentence embeddings for\n",
    "query = \"How many people live in London?\"\n",
    "docs = [\"Around 9 Million people live in London\", \"London is known for its financial district\"]\n",
    "\n",
    "#Encode query and docs\n",
    "query_emb = encode(query)\n",
    "doc_emb = encode(docs)\n",
    "\n",
    "#Compute dot score between query and all document embeddings\n",
    "scores = (query_emb @ tf.transpose(doc_emb))[0].numpy().tolist()\n",
    "\n",
    "#Combine docs & scores\n",
    "doc_score_pairs = list(zip(docs, scores))\n",
    "\n",
    "#Sort by decreasing score\n",
    "doc_score_pairs = sorted(doc_score_pairs, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "#Output passages & scores\n",
    "for doc, score in doc_score_pairs:\n",
    "    print(f\"Score: {score:.2f}, Query: {doc}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015ae4b7-20b2-4af6-8869-8327ceb7c495",
   "metadata": {},
   "source": [
    "# Benchmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f13beeb-a70e-4791-a9d5-e8df4a8ce7a5",
   "metadata": {},
   "source": [
    "## Objective: Benchmark Performing Comparisons\n",
    "\n",
    "Benchmark embeddings comparison for all Show Descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "cf2e6f10-574b-41b1-b271-31895d07d047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35s to compare a worst cast dot product with 100000 rows.\n"
     ]
    }
   ],
   "source": [
    "randomquery_raw = \"Random Query\"\n",
    "random_query = encode(randomquery_raw)\n",
    "large_embed = tf.constant(np.random.random((100000,384)), dtype=tf.float32)\n",
    "start = time.time()\n",
    "scores = (random_query @ tf.transpose(large_embed))[0].numpy().tolist()\n",
    "end = time.time()\n",
    "print(f\"{end-start:.2f}s to compare a worst cast dot product with 100000 rows.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9251cb4-301c-4aa1-98b9-58be8a034820",
   "metadata": {},
   "source": [
    "## Objective: Benchmark Making Show Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "4b04f5ae-79db-48db-a5d7-de5c6653d459",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df.drop_duplicates(['show_name','show_description'])[['show_name','show_description']].reset_index(drop=True)\n",
    "show_descriptions = list(df_filtered['show_description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "28228ae9-8944-4839-aaee-753c5dc60990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08s: 1 Show Embedding(s)\n",
      "0.09s: 3 Show Embedding(s)\n",
      "0.12s: 10 Show Embedding(s)\n",
      "0.27s: 30 Show Embedding(s)\n",
      "1.10s: 100 Show Embedding(s)\n",
      "9.62s: 300 Show Embedding(s)\n"
     ]
    }
   ],
   "source": [
    "# Note: on show description embedding size of 1000, my macbook ran out of memory.\n",
    "t = []\n",
    "for i in [1, 3, 10, 30, 100, 300]:\n",
    "    start = time.time()\n",
    "    shows_embeddings = encode(show_descriptions[:i])\n",
    "    end = time.time()\n",
    "    t.append(end-start)\n",
    "    print(f\"{end-start:.2f}s: {i} Show Embedding(s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "66fc0b4b-bbbd-484e-a521-d608a129a5ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Show Embeddings size: 30.  Maximizes Embeddings Per Second on my local machine\n"
     ]
    }
   ],
   "source": [
    "embedding_size_trials = np.array([1, 3, 10, 30, 100, 300])\n",
    "# take the embedding size trials and then take the argmax of the Embeddings Per Second Metric\n",
    "# which gives you the best index from embedding_size_trials.  this becomes the best_size.\n",
    "embeddings_per_sec = embedding_size_trials / np.array(t)\n",
    "best_index = np.argmax(embeddings_per_sec)\n",
    "best_size = embedding_size_trials[best_index]\n",
    "print(f\"Best Show Embeddings size: {best_size}.  Maximizes Embeddings Per Second on my local machine\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "8e25ef85-00d2-4c0e-b06f-3bc8b19fbd90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.39 minutes to create all show embeddings.\n"
     ]
    }
   ],
   "source": [
    "# To attempt embeddings for each show...\n",
    "# create 30 embeddings at a time would take: \n",
    "print(f\"{df_filtered.shape[0] / embeddings_per_sec[best_index] / 60 :.2f} minutes to create all show embeddings.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8401edc7-9a56-4fc9-ac60-81f4ab8f77b0",
   "metadata": {},
   "source": [
    "## Objective: Benchmark Making Episode Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "9c776b4f-ad81-4403-ae57-68b1d132406d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df.drop_duplicates(['show_name','show_description'])[['show_name','show_description']].reset_index(drop=True)\n",
    "episode_descriptions = list(df['episode_description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "3e80961b-ba11-4b1c-a661-39c8b098ad43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16s: 1 Episode Embedding(s)\n",
      "0.12s: 3 Episode Embedding(s)\n",
      "0.20s: 10 Episode Embedding(s)\n",
      "0.76s: 30 Episode Embedding(s)\n",
      "4.25s: 100 Episode Embedding(s)\n"
     ]
    }
   ],
   "source": [
    "# Note: on show description embedding size of 1000, my macbook ran out of memory.\n",
    "t = []\n",
    "for i in [1, 3, 10, 30, 100]:\n",
    "    start = time.time()\n",
    "    episode_embeddings = encode(episode_descriptions[:i])\n",
    "    end = time.time()\n",
    "    t.append(end-start)\n",
    "    print(f\"{end-start:.2f}s: {i} Episode Embedding(s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "35e766e4-f609-4caf-b365-ee4175c9eddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Episode Embeddings size: 10.  Maximizes Embeddings Per Second on my local machine\n"
     ]
    }
   ],
   "source": [
    "embedding_size_trials = np.array([1, 3, 10, 30, 100])\n",
    "# take the embedding size trials and then take the argmax of the Embeddings Per Second Metric\n",
    "# which gives you the best index from embedding_size_trials.  this becomes the best_size.\n",
    "embeddings_per_sec = embedding_size_trials / np.array(t)\n",
    "best_index = np.argmax(embeddings_per_sec)\n",
    "best_size = embedding_size_trials[best_index]\n",
    "print(f\"Best Episode Embeddings size: {best_size}.  Maximizes Embeddings Per Second on my local machine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "bc292021-b450-4dc6-ad21-ac63b9168335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.56 minutes to create all episode embeddings.\n"
     ]
    }
   ],
   "source": [
    "# To attempt embeddings for each show...\n",
    "# create 30 embeddings at a time would take: \n",
    "print(f\"{df.shape[0] / embeddings_per_sec[best_index] / 60 :.2f} minutes to create all episode embeddings.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d68d1c6-0dc2-461f-8979-f4242a575a4d",
   "metadata": {},
   "source": [
    "# Test Code for Generating encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "7bbd3bc5-4068-411f-8354-13b49ff1f914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame with text key (column: show_name) and text to embed (column: show_description) \n",
    "df_filtered = df.drop_duplicates(['show_name','show_description'])[['show_name','show_description']].reset_index(drop=True)\n",
    "\n",
    "# Create blocks of data and call encode\n",
    "# Save the data in a systematic way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "e16c77ef-05f9-475c-9f49-e432cff9abf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block size\n",
    "block_size = 30\n",
    "\n",
    "# Iterate over consecutive blocks of rows\n",
    "num_rows = len(df_filtered)\n",
    "start_index = 0\n",
    "counter = 0\n",
    "while start_index < num_rows:\n",
    "    end_index = start_index + block_size if start_index + block_size < num_rows else num_rows\n",
    "    subset_df = df.iloc[start_index:end_index]\n",
    "\n",
    "    # Apply the encode function to the current block\n",
    "    #encode_function(subset_df)\n",
    "    #save_data(subset_df\n",
    "    start_index = end_index\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "f7cbcaef-08de-4b04-924e-5c8b649b8274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example data structure of embeddings being saved.\n",
    "embedding_size = 384\n",
    "block_size = 30\n",
    "num_blocks = 3\n",
    "num_padding = 5\n",
    "files = []\n",
    "for i in range(num_blocks):\n",
    "    # fake data\n",
    "    d = {\n",
    "        \"block\":i,\n",
    "        \"show_names\":['show1','show2','show3'] * 10,\n",
    "        \"show_desc_embeddings\": np.ones((block_size,embedding_size))*i\n",
    "    }\n",
    "    block_num = d['block']\n",
    "    filename = f\"{block_num:0{num_padding}}_data.pkl\"\n",
    "    files.append(filename)\n",
    "    # Save to disk\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(d, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "6bca1076-b984-414a-889c-d80017afc507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 384) 90\n"
     ]
    }
   ],
   "source": [
    "def extract_shows(filenames):\n",
    "    \"\"\"\n",
    "    input args:\n",
    "        files - list of files used to save the embeddings.\n",
    "    return args: \n",
    "        embedding_matrix - a numpy array of size (block_size x num_blocks,embedding_size) \n",
    "        list_of_shows - a list of strings of len (block_size x num_blocks)\n",
    "    \"\"\"\n",
    "    # This code takes in a list of files, then loads them, \n",
    "    # extracts the embeddings and concatenates them with the other embeddings.\n",
    "    list_of_tensors = []\n",
    "    list_of_shows = []\n",
    "    for file in filenames: \n",
    "        # Load from disk\n",
    "        with open(file, 'rb') as f:\n",
    "            loaded_data = pickle.load(f)\n",
    "        list_of_tensors.append(loaded_data['show_desc_embeddings'])\n",
    "        list_of_shows.extend(loaded_data['show_names'])\n",
    "    \n",
    "    embedding_matrix = np.vstack(list_of_tensors)\n",
    "    return embedding_matrix, list_of_shows\n",
    "\n",
    "a,b= extract_shows(files)\n",
    "print(a.shape, len(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1d9621-054e-44a3-b2bf-3b518031a461",
   "metadata": {},
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
